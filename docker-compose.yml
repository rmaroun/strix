version: "3.9"

services:
  strix:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: strix
    # The entrypoint script in the image will run first, then this command executes.
    command: >
      python -m strix.runtime.tool_server
      --token ${STRIX_TOKEN}
      --host 0.0.0.0
      --port 8000
    environment:
      # Required
      STRIX_SANDBOX_MODE: "true"
      STRIX_TOKEN: ${STRIX_TOKEN}
      CAIDO_PORT: "8085"
      # Optional model config
      STRIX_LLM: ${STRIX_LLM:-openai/gpt-5}
      LLM_API_KEY: ${LLM_API_KEY:-}
      LLM_API_BASE: ${LLM_API_BASE:-}
      PERPLEXITY_API_KEY: ${PERPLEXITY_API_KEY:-}
    ports:
      - "8000:8000"   # FastAPI tool server
      - "8085:8085"   # Caido local proxy (optional to expose)
    volumes:
      - strix_workspace:/workspace
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8000/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    # If you see DNS issues on some hosts, uncomment:
    # dns:
    #   - 1.1.1.1
    #   - 8.8.8.8

volumes:
  strix_workspace:
